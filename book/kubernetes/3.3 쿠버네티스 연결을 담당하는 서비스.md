# 쿠버네티스 연결을 담당하는 서비스
- 쿠버네티스 클러스터 내부에서 파드를 사용할 수 있다. 또한 외부 사용자가 파드를 이용하는 방법도 있다.
- `서비스`: 외부에서 쿠버네티스 클러스터에 접속하는 방법 (소비를 위한 도움을 제공한다는 관점)

## ✅ 가장 간단하게 연결하는 노드포트
`노드 포트` 서비스를 설정하면 모든 워커 노드의 특정 포트(노드포트)를 열고 여기로 오는 모든 요청을 노드포트 서비스로 전달한다.

### 노드포트 서비스로 외부에서 접속하기
 
```shell
# m-k8s at super putty
kubectl create deployment np-pods --images=sysnet4admin/echo-hname
kubectl get pods
kubectl create -f ~/BookInfra/ch3/3.3.1/nodeport.yaml
kubectl get services
kubectl get nodes -o wide
```
1. 디플로이먼트로 파드를 생성한다. 이때 이미지는 sysnet4admin 계정에 있는 echo-hname 을 사용한다.
2. 배포된 파드를 확인한다.
3. kubectl create 노드포트 서비스를 생성한다. 편의를 위해 이미 정의한 오브젝트 스펙을 이용한다.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: np-svc
spec:
  selector:
    app: np-pods 
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 80
      nodePort: 30000
  type: NodePort
```
- metadata.name: 서비스 이름
- spec.selector: 셀렉터의 레이블 지정
- spec.ports: 사용할 프로토콜과 포트들을 지정
- spec.type: 서비스 타입을 설정
    > 기존 파드 구조에서 kind 가 Service 로 바뀌었고, spec 에 컨테이너에 대한 정보가 없다.
    > 그리고 접속에 필요한 네트워크 관련 정보(protocol, port, targetPort, nodePort) 와 서비스의 type 을 NodePort 로 지정했다.

4. kubectl get services 를 실행해 노드포트 서비스로 생성한 np-svc 서비스를 확인한다.
- `PORT(S)` 컬럼에서 노드포트의 포트 번호 확인한다. `CLUSTER-IP` 는 쿠버네티스 클러스터의 내부에서 사용하는 IP로, 자동으로 지정된다.
5. 쿠버네티스 클러스터의 워커 노드 IP 를 확인한다.
```http request
192.168.1.101 ~ 103
```
6. 호스트 노트북에서 웹 브라우저를 띄우고 192.168.1.101~103(확인한 워커 노드의 IP)와 30000번(노트포트의 포트 번호)으로 접속해 외부에서 접속되는지 확인한다.
화면에 파드 이름이 표시되는지도 확인한다. 이때 파드가 하나이므로 화면에 보이는 이름은 모두 동일하다.

### 부하 분산 테스트하기
부하가 분산되는지(로드밸런서 기능) 확인한다. 디플로이먼트로 생성된 파드 1개에 접속하고 있는 중에 파드가 3개로 증가하면 접속이 어떻게 바뀌는지 확인한다.
```powershell
$i=0; while($true) \
{ \
% { $i++; write-host -NoNewline "$i $_" } \
(Invoke-RestMethod "http://192.168.1.101:30000")-replace '\n', " " \
}
```
1. 현재 접속한 호스트 이름을 순서대로 출력한다.
호스트 노트북(또는 PC) 에서 파워쉘 명령창에서 실행한다. 이 명령은 반복적으로 192.168.1.101:30000에 접속해 접속한 파드 이름을 화면에 표시(Invoke-RestMethod)한다.
이렇게 하면 파드가 1개에서 3개로 늘어나는 시점을 관찰할 수 있다.

```shell
# m-k8s at super putty
kubectl scale deployment np-pods --replicas=3
kubectl get pods
```
2. 쿠버네티스 마스터 노드에서 scale 을 실행해 파드를 3개로 증가 시킨다.
3. 배포된 파드를 확인한다.
4. 파워쉘 명령 창을 확인해 표시하는 파드 이름에 배포딘 파드 3개가 돌아가면서 표시되는지 확인한다. 즉 부하 분산이 제대로 되는지 확인한다.

- 어떻게 추가된 파드를 외부에서 추적해 접속하는 건가?
  - `노트포트의 오브젝트 스펙에 적힌 np-pods` 와 `디플로이먼트의 이름`을 확인해 동일하면 같은 파드라고 간주하기 때문이다.
  - 추적 방법은 많지만, 여기서는 가장 간단하게 이름으로 진행하였다.

### expose 로 노드포트 서비스 생성하기
노드포트 서비스는 `오브젝트 스펙 파일`과 `expose 명령어`로 생성할 수 있다.

```shell
# m-k8s at super putty
kubectl expose deployment np-pods --type=NodePort --name=np-svc-v2 --port=80
kueectl get services
```
1. expose 명령어를 사용해 서비스로 내보낼 디플로이먼트를 np-pods 로 지정한다. 
2. 생성된 서비스를 확인한다. expose 를 사용하면 오브젝트 스펙으로 생성할 때처럼 노드포트의 포트번호를 지정할 수 없다. 포트 번호는 30000~32767에서 임의로 지정된다.

```http request
192.168.1.101:32122
```
3. 호스트 노트북(또는 PC) 에서 웹 브라우저를 띄우고 192.168.1.101:32122(무작위로 생성된 포트 번호)에 접속한다. 배포된 파드 중 하나의 이름이 웹 브라우저에 표시되는지 확인한다.

```shell
# m-k8s at super putty
kubectl delete deployment np-pods
kubectl delete services np-svc
kubectl delete services np-svc-v2
```
4. 다음 실습 진행을 위해 배포한 디플로이먼트와 서비스 2개를 모두 삭제한다.

## ✅ 사용 목적별로 연결하는 인그레스
`인그레스`(Ingress)는 고유한 주소를 제공해 사용 목적에 따라 다른 응답을 제공할 수 있고, 트래픽에 대한 L4/L7 로드밸런서와 보안 인증서를 처리하는 기능을 제공한다.
노드포트 서비스는 포트를 중복 사용할 수 없어서 1개의 노드포트에 1개의 디플로이먼트만 적용된다. 여러 개의 디플로이먼트가 있을 때 그 수만큼 노트포트 서비스를 구동하지 않고 인그레스를 사용한다.
인그레스를 사용하려면 `인그레스 컨트롤러`가 필요하다. 다양한 인그레스 컨트롤러가 있지만, 쿠버네티스에서 프로젝트로 지원하는 `NGINX 인그레스 컨트롤러`로 구성해 본다.

### NGINX 인그레스 컨트롤러 작동 순서
1. 사용자는 노드마다 설정된 노드포트를 통해 노드포트 서비스로 접속한다. 이때 노드포트 서비스를 NGINX 인그레스 컨트롤러로 구성한다.
2. NGINX 인그레스 컨트롤러는 사용자의 접속 경로에 따라 적합한 클러스터 IP 서비스로 경로를 제공한다.
3. 클러스터 IP 서비스는 사용자를 해당 파드로 연결한다.

> 인그레스 컨트롤러는 파드와 직접 통신할 수 없어서 노드포트 또는 로드밸러서 서비스와 연동되어야 한다. 따라서 노드포트로 이를 연동했다.

> 인그레스 컨트롤러의 궁극적인 목적은 사용자가 접속하는 경로에 따라 다른 결괏값을 제공하는 것이다.

```shell
# m-k8s at super putty
kubectl create deployment in-hname-pod --image=sysnet4admin/echo-hname
kubectl create deployment in-ip-pod --image=sysnet4admin/echo-ip
kubectl get pods
kubectl apply -f ~/_Book_k8sInfra/ch3/3.3.2/ingress-nginx.yaml
kubectl get pods -n ingress-nginx
kubectl apply -f ~/_Book_k8sInfra/ch3/3.3.2/ingress-config.yaml
```
1. 테스트용으로 디플로이먼트 2개 (in-hname-pod, in-ip-pod)를 배포한다.
2. 테스트용으로 디플로이먼트 2개 (in-hname-pod, in-ip-pod)를 배포한다.
3. 배포된 파드의 상태를 확인한다.
4. NGINX 인그레스 컨트롤러를 설치한다. 여기에는 많은 종류의 오브젝트 스펙이 포함한다. 설치되는 요소들은 NGINX 인그레스 컨트롤러 서비스를 제공하기 위해 미리 지정돼 있다.
5. NGINX 인그레스 컨트롤러의 파드가 배포됐는지 확인한다. NGINX 인그레스 컨트롤러는 default 네임스페이스가 아닌 ingress-nginx 네임스페이스에 속하므로 -n ingress-nginx 옵션을 추가한다.
6. 인그레스를 사용자 요구 사항에 맞게 설정하려면 경로와 작동을 정의해야 한다. 파일로도 설정할 수 있으므로 다음 경로로 실행해서 미리 정의해 둔 설정을 적용한다.

```yaml
apiVersion: networking.k8s.io/v1beta1
kind: Ingress
metadata:
  name: ingress-nginx
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - http:
      paths:
      - path:
        backend:
          serviceName: hname-svc-default
          servicePort: 80
      - path: /ip
        backend:
          serviceName: ip-svc
          servicePort: 80
      - path: /your-directory
        backend:
          serviceName: your-svc
          servicePort: 80
```
이 파일은 들어오는 주소 값과 포트에 따라 노출된 서비스를 연결하는 역할을 설정한다. 외부에서 주소 값과 노드포트를 가지고 들어 오는 것은 hname-svc-default 서비스와 연결된 파드로 넘기고, 외부에서 들어오는 주소 값, 노드포트와 함께 뒤에 /ip 를 추가한 주소 값은 ip-svc 서비스와 연결된 파드로 접속하게 설정한다.
- metadata.name: 서비스 이름
- metadata.namespace: 네임스페이스 이름
- spec.rules: 규칙을 지정
- spec.rules-http.paths-path: 기본 경로 규칙
- spec.rules-http.paths-backend: 연결되는 서비스와 포트
- spec.rules-http.paths-path: /ip : 기본 경로에 ip 라는 이름의 경로 추가

```shell
# m-k8s at super putty
kubectl get ingress
kubectl get ingress -o yaml
kubectl apply -f ~/_Book_k8sInfra/ch3/3.3.2/ingress.yaml
```
7. 인그레스 설정 파일이 제대로 등록됐는지 kubectl get ingress 로 확인한다.
8. 인그레스에 요청한 내용이 확실하게 적용됐는지 확인한다. 이 명령은 인그레스에 적용된 내용을 야믈 형식으로 출력해 적용된 내용을 확인할 수 있다.
9. NGINX 인그레스 컨트롤러 생성과 인그레스 설정을 완료했다. 이제 외부에서 NGINX 인그레스 컨트롤러에 접속할 수 있게 노드포트 서비스로 NGINX 인그레스 컨트롤러를 외부에 노출한다.

```yaml
apiVersion: v1
kind: Service
metadata:
  name: nginx-ingress-controller
  namespace: ingress-nginx
spec:
  ports:
  - name: http
    protocol: TCP
    port: 80
    targetPort: 80
    nodePort: 30100
  - name: https
    protocol: TCP
    port: 443
    targetPort: 443
    nodePort: 30101
  selector:
    app.kubernetes.io/name: ingress-nginx
  type: NodePort
```
- metadata.name: Ingress 의 이름, 이름을 통해서 통신할 ingress 컨트롤러 확인
- metadata.annotations: 메타데이터의 기록 및 변경, 여기선 rewrite-target 을 /(기본 주소)로 지정함.
- spec.ports: 사용할 프로토콜과 포트들을 지정
- spec.ports-name: http에 대한 프로토콜 및 포트 지정
- spec.selector: 셀렉터의 레이블 지정
- spec.type: 서비스 타입을 설정

```shell
# m-k8s at super putty
kubectl get services -n ingress-nginx
kubectl expose deployment in-hname-pod --name=hname-svx-default --port=80,443
kubectl expose deployment in-ip-pod --name=ip-svc --port=80,443
kubectl get services
```
10. 노드포트 서비스로 생성된 NGINX 인그레스 컨트롤러를 확인한다.
11. expose 명령으로 디플로이먼트(in-hname-pod, in-ip-pod)도 서비스로 노출한다. 외부와 통신하기 위해 클러스터 내부에서만 사용하는 파드를 클러스터 외부에 노출할 수 있는 구역으로 옮기는 것이다.
내부와 외부 네트워크를 분리해 관리하는 DMZ 와 유사한 기능이다. `비유적으로 표현하면 각 방에 있는 물건을 외부로 내보내기 전에 공용 공간인 거실로 모두 옮기는 것과 같다.`
12. 생성된 서비스를 점검해 디플로이먼트들이 서비스에 정상적으로 노출되는지 확인한다. 새로 생성된 서비스는 default 네임스페이스에 있으므로 -n 옵션으로 네임스페이스를 지정하지 않아도된다.

```http request
192.168.1.101:30100
192.168.1.101:30100/ip
https://192.168.1.101:30101
https://192.168.1.101:30101/ip
```
13. 호스트 노트북(또는 PC) 에서 웹 브라우저를 띄우고 192.168.1.101:30100 에 접속해 외부에서 접속되는 경로에 따라 다르게 작동하는지 확인한다.
이때 워커 노드 IP는 192.168.1.101 이 아닌 102 또는 103 을 사용해도 무방하다.
14. /ip 를 추가한다. 요청 방법과 파드의 ip (CIDR로 임의 생성된다.)가 반환되는지 확인한다.
15. https://192.168.1.101:30101 으로 접속해 HTTP 연결이 아닌 HTTPS 연결도 정상적으로 작동하는지 확인한다. 파드 이름이 브라우저에 표시되는지 확인한다.
16. /ip 를 추가한다. 요청 방법과 파드의 IP 주소가 웹 브라우저에 표시된다.

```shell
# m-k8s at super putty
kubectl delete deployment in-hname-pod
kubectl delete deployment in-ip-pod
kubectl delete services hname-svc-default
kubectl delete services ip-svc
kubectl delete -f ~/_Book_k8sInfra/ch3/3.3.2/ingress-nginx.yaml
kubectl delete -f ~/_Book_k8sInfra/ch3/3.3.2/ingress-config.yaml
```
17. NGINX 인그레스 컨트롤러 구성과 테스트가 끝났다. 역시 다음 실습 진행을 위해 배포한 디플로이먼트와 모든 서비스를 삭제한다.
18. NGINX 인그레스 컨트롤러 구성과 테스트가 끝났다. 역시 다음 실습 진행을 위해 배포한 디플로이먼트와 모든 서비스를 삭제한다.
19. NGINX 인그레스 컨트롤러 구성과 테스트가 끝났다. 역시 다음 실습 진행을 위해 배포한 디플로이먼트와 모든 서비스를 삭제한다.
20. NGINX 인그레스 컨트롤러 구성과 테스트가 끝났다. 역시 다음 실습 진행을 위해 배포한 디플로이먼트와 모든 서비스를 삭제한다.
21. NGINX 인그레스 컨트롤러와 관련된 내용도 모두 삭제한다. 여러 가지 내용이 혼합됐으므로 설치 파일을 이용해 삭제하기를 권장한다.
22. NGINX 인그레스 컨트롤러와 관련된 내용도 모두 삭제한다. 여러 가지 내용이 혼합됐으므로 설치 파일을 이용해 삭제하기를 권장한다.

## ✅ 클라우드에서 쉽세 구성 가능한 로드밸런서
앞에서 배운 연결 방식은 들어오는 요청을 모두 워커 노드의 노트포트를 통해 노드포트 서비스로 이동하고 이를 다시 쿠버네티스의 파드로 보내는 구조이다. `비효율적인 방식` 이다.
쿠버네티스에서 `로드밸런서`라는 서비스 타입을 제공해 파드를 외부에 노출하고 부하를 분산한다.
클라우드에서 제공하는 쿠버네티스를 사용하고 있다면 아래와 같이 선언만 하면 된다. 
```shell
# 클라우드 사(EKS, GKE, AKS)에서만 가능
kubectl expose deployment ex-lb --type=LoadBalancer --name=ex-svc
kubectl get services ex-svc 
```
1. 쿠버네티스 클러스터에 로드밸런서 서비스가 생성돼 외부와 통신할 수 있는 IP(EXTERNAL-IP)가 부여되고 외부와 통신할 수 있으며 부하도 분산된다.

## ✅ 온프레미스에서 로드밸런서를 제공하는 MetalLB

### `MetalLB`란?
온프레미스에서 로드밸런서를 사용하려면 내부에 로드밸런서 서비스를 받아주는 구성이 필요한데, 이를 지원하는 것이다. 베어메탈로 구성된 쿠버네티스에서도 로드밸런서를 사용할 수 있게 고안된 프로젝트이다.
MetalLB는 특별한 네트워크 설정이나 구성이 있는 것이 아니라 기존의 L2 네트워크(ARP/NDP)와 L3 네트워크(BGP)로 로드밸런서를 구현한다.
## ✅ 부하에 따라 자동으로 파드 수를 조절하는 HPA
