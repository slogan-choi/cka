# 쿠버네티스 이해하기

## ✅ 쿠버네티스
쿠버네티스는 `컨테이너 오케스트레이션`을 위한 솔루션이다.
다수의 컨테이너를 유기적으로 연결, 실행, 종료할 뿐 아니라 상태를 추적하고 보존하는 등 컨테이너를 안정적으로 사용할 수 있게 만들어주는 것이 컨테이너 오케스트레이션이다.

## ✅ 쿠버네티스 구성하기
- kubeadm 으로 쿠버네티스 구성
```shell
#!/usr/bin/env bash
# master_node.sh

# init kubernetes 
kubeadm init --token 123456.1234567890123456 --token-ttl 0 \
--pod-network-cidr=172.16.0.0/16 --apiserver-advertise-address=192.168.1.10 

# config for kubernetes's network 
kubectl apply -f \
https://raw.githubusercontent.com/sysnet4admin/IaC/master/manifests/172.16_net_calico.yaml
```
1. kubeadm 을 통해 쿠버네티스의 워커 노드를 받아들일 준비를 한다.
먼저 토큰을 123456.1234567890123456 으로 지정하고 ttl(유지되는 시간)을 0으로 설정해서 기본값인 24시간 후에 토큰이 계속 유지되게 한다.
그리고 워커 노드가 정해진 토큰으로 들어오게 한다.
쿠버네티스가 자동으로 컨테이너에 부여되는 네트워크를 172.16.0.0/16 (172.16.0.1 ~ 172.16.255.254) 으로 제공하고, 워커 노드가 접속하는 API 서버의 IP 를 192.168.1.10 으로 지정해 워커 노드들이 자동으로 API 서버에 연결되게 한다.
2. 컨테이너 네트워크 인터페이스(CNI) 인 캘리코(Calico) 의 설정을 적용해 쿠버네티스의 네트워크를 구성한다.

```shell
#!/usr/bin/env bash
# work_nodes.sh

# config for work_nodes only 
kubeadm join --token 123456.1234567890123456 \
             --discovery-token-unsafe-skip-ca-verification 192.168.1.10:6443
```
1. kubeadm 을 이용해 쿠버네티스 마스터 노드에 접속한다.
이때 연결에 필요한 토큰은 기존에 마스터 노드에서 생성한 123456.1234567890123456 을 사용한다.
간단하게 구성하기 위해 --discovery-token-unsafe-skip-ca-verification 으로 인증을 무시하고, API 서버 주소인 192.168.1.10 으로 기본 포트 번호인 6443번 포트에 접속하도록 설장한다.

```shell
# m-k8s at super putty
kubectl get nodes
```
1. kubectl get nodes 명령으로 쿠버네티스 클러스터에 마스터 노드와 워커 노드들이 정상적으로 생성되고 연결됐는지 확인한다.

## ✅ 파드 배포를 중심으로 쿠버네티스 구성 요소 살펴보기
```shell
# m-k8s at super putty
kubectl get pods --all-namespaces
kubectl get pods --all-namespaces | grep kube-proxy
kubectl get pods --all-namespaces | grep coredns
```
1. --all-namespaces 는 기본 네임스페이스인 default 외에 모든 것을 표시하겠다는 의미이다. 따라서 모든 네임스페이스에서 파드를 수집해 보여준다. 쿠버네티스 클러스터를 이루는 구성 요소들은 파드 형태로 이루어져 있음을 알 수 있다.
2. 쿠버네티스 구성 요소는 동시에 여러 개가 존재하는 경우 중복된 이름을 피하려고 뒤에 해시(hash) 코드가 삽입된다.
3. coredns 에는 중간에 문자열이 하나 더 있는데, 이는 레플리카셋(ReplicaSet) 을 무작위 문자열로 변행해 추가한 것이다.

### 관리자나 개발자가 파드를 배포할 때
- 0번~7번 기본 설정으로 쿠버네티스에서 이루어지는 통신 단계를 구분한 것이다.
#### 마스터 노드
0. `kubectl`: 쿠버네티스 클러스터에 명령을 내리는 역할 한다. 바로 실행되는 명령 형태인 바이너리(binary)로 배포된다.
1. `API 서버`: 쿠버네티스 클러스터의 중심 역할을 하는 통로이다. 주로 상태 값을 저장하는 etcd 와 통신하지만, 그 밖의 요소들 또한 API 서버를 중심에 두고 통신하므로 API 서버의 역할이 매우 중요하다.
2. `etcd[엣시디]`: 구성 요소들의 상태 값이 모두 저장되는 곳이다. etcd 외의 다른 구성 요소는 상태 값을 관리하지 않는다. 그러므로 etcd 의 정보만 백업돼 있다면 긴급한 장애 상황에서도 쿠버네티스 클러스터는 복구할 수 있다.
또한, etcd 는 분산 저장이 가능한 key-value 저장소이므로, 복제해 여러 곳에 저장해 두면 하나의 etcd 에서 장애가 나더라도 시스템의 가용성을 확보할 수 있다. 
3. `컨트롤러 매니저`: 쿠버네티스 클러스터의 오브젝트 상태를 관리한다. 다양한 상태 값을 관리하는 주체들이 컨트롤러 매니저에 소속돼 각자의 역할을 수행한다.
4. `스케줄러`: 노드의 상태와 자원, 레이블, 요구 조건 등을 고려해 파드를 어떤 워커 노드에 생성할 것인지를 결정하고 할당한다. 파드를 조건에 맞는 워커 노드에 지정하고, 파드가 워커 노드에 할당되는 일정을 관리하는 역할을 담당한다.

#### 워커 노드
5. `kubelet`: 파드의 구성 내용(PodSpec) 을 받아서 컨테이너 런타임으로 전달하고, 파드 안의 컨테이너들이 정상적으로 작동하는지 모니터링한다.
6. `컨테이너 런타임(CRI)`: 파드를 이루는 컨테이너의 실행을 담당한다. 파드 안에서 다양한 종류의 컨테이너가 문제 없이 작동하게 만드는 표준 인터페이스이다. 
7. `파드(Pod)`: 한 개 이상의 컨테이너로 단일 목적의 일을 하기 위해서 모인 단위이다. 즉, 웹 서버 역할을 할 수도 있고 로그나 데이터를 분석할 수 있다.
여기서 중요한 것은 파드는 `언제라도 죽을 수 있는 존재` 라는 점이다.

#### 선택 가능한 구성요소
- 선택적으로 배포하는 것들은 순서와 상관이 없기 때문에 10번대로 구분해 표시한다.
11. `네트워크 플러그인`: 쿠버네티스 클러스터의 통신을 위해서 네트워크 플러그인을 선택하고 구성해야 한다. 네트워크 플러그인은 일반적으로 CNI 로 구성한다.
12. `CoreDNS`: 클라우드 네이티브 컴퓨팅 재단에서 보증하는 프로젝트로, 빠르고 유연한 DNS 서버이다. 쿠버네티스 클러스터에서 도메인 이름을 이용해 통신하는데 사용한다.
**실무에서 쿠버네티스 클러스터를 구성하여 사용할 때는 IP 보다 도메인 네임을 편리하게 관리해 주는 CoreDNS 를 사용하는 것이 일반적이다.**

### 사용자가 배포된 파드에 접속할 때
- 파드가 배포된 이후 사용자 입장에서 배포된 파드에 접속하는 과정을 살펴본다.
1. `kube-proxy`: 쿠버네티스 클러스터는 파드가 위치한 노드에 kube-proxy 를 통해 파드가 통신할 수 있는 네트워크를 설정한다. 이때 실제 통신은 br_netfilter 와 iptables로 관리한다.
2. `파드`: 이미 배포된 파드에 접속하고 필요한 내용을 전달받는다. 이때 대부분 사용자는 파드가 어느 워크 노드에 위치하는지 신경 쓰지 않아도 된다.

## ✅ 파드의 생명주기로 쿠버네티스 구성 요소 살펴보기
- 파드가 배포되는 과정을 하나하나 자세히 살펴보면서 쿠버네티스의 구성 요소들이 어떤 역할을 담당하는지 정리한다.

1. `Pod(s) 생성 요청`:
kubectl 을 통해 API 서버에 파드 생성을 요청한다.
2. `(매번) 클러스터의 업데이트된 정보 기록, (매번) API 서버에 업데이트 됐음을 알림`:
   (업데이트가 있을 때마다 매번) API 서버에 전달된 내용이 있으면 API 서버는 etcd 에 전달된 내용을 모두 기록해 클러스터의 상태 값을 최신으로 유지한다. 따라서 각 요소가 상태를 업데이트할 때마다 모두 API 서버를 통해 etcd 에 기록한다.
3. `Pod(s) 의 생성 감시, Pod(s)의 생성`: 
API 서버에 파드 생성이 요청된 것을 컨트롤러 매니저가 인지하면 컨트롤러 매니저는 파드를 생성하고, 이 상태를 API 서버에 전달한다. 참고로 아직 어떤 워커 노드에 파드를 적용할지는 결정되지 않은 상태로 파드만 생성된다.
4. `새로운 Pod(s)가 워커 노드에 들어갔는지 감시, 새로운 Pod(s)를 워커 노드에 넣도록 스케줄링`: 
API 서버에 파드가 생성됐다는 정보를 스케줄러가 인지한다. 스케줄러는 생성된 파드를 어떤 워커 노드에 적용할지 조건을 고려해 결정하고 해당 워커 노드에 파드를 띄우도록 요청한다.
5. `새로운 Pod(s)가 노드에 잘 소속돼 있는지 감시, Pod(s) 상태 정보 전달`:
API 서버에 전달된 정보대로 지정한 워커 노드에 파드가 속해 있는지 스케줄러가 kubelet 으로 확인한다.
6. `Pod(s)의 동작 관리`: kubelet 에서 컨테이너 런타임으로 파드 생성을 요청한다.
7. `컨테이너 생성`: 파드가 생성된다.
8. `Pod(s) 사용가능`: 파드가 사용 가능한 상태가 된다.

> 쿠버네티스는 작업을 순서대로 진행하는 워크플로 구조가 아니라 선언적인 시스템 구조를 가지고 있다. 즉, 각 요소가 `추구하는 상태` 를 선언하면 `현재 상태`와 맞는지 점검하고 그것에 맞추려고 노력하는 구조로 돼 있다.

## ✅ 쿠버네티스 구성 요소의 기능 검증하기
- 시나리오를 작성해 구성 요소들의 역할과 의미를 확인한다.

### kubectl
```shell
# w3-k8s at super putty
kubectl get nodes --kubeconfig admin.conf
```
1. kubctl get nodes 명령에 추가로 쿠버네티스 클러스터 정보를 입력받는 옵션(--kubeconfig) 과 마스터 노드에서 받아온 쿠버네티스 클러스터의 정보(/etc/kubernetetes/admin.conf) 를 입력하고 실행한다.

### kubelet
- kubelet은 쿠버네티스에서 파드의 생성과 상태 관리 및 복구 등을 담당하는 매우 중요한 구성 요소이다. 따라서 kubelet 에 문제가 생기면 파드가 정상적으로 관리되지 않는다.
```shell
# m-k8s at super putty
kubectl create -f ~/_Book_k8sInfra/ch3/3.1.6/nginx-pod.yaml
kubectl get pod
kubectl get pods -o -wide
```
1. 파드의 구성 내용을 파일로 읽어 들여 1개의 파드를 임의의 워커 노드에 배포하는 것
2. 배포된 파드가 정상적으로 배포된 상태(Running) 인지 확인한다.
3. 파드가 배포된 워커 노드를 확인한다.

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: nginx-pod
spec:
  containers:
  - name: container-name
    image: nginx
```
1. metadata.name: 파드의 이름
2. spec.containers: 파드에서 호출할 컨테이너 이미지 지정

```shell
# w2-k8s at super putty
systemctl stop kubelet
```
4. kubelet 서비스를 멈춘다. 스케줄러가 임의의 노드를 지정해 배포한다.

```shell
# m-k8s at super putty
kubectl get pod
kubectl delete pod nginx-pod
kubectl get pod
```
5. 상태를 확인하고 파드를 삭제한다. (파드 삭제하는데 오래 걸린다.)

```shell
# w2-k8s at super putty
systemctl start kubelet
```
6. kubelet 을 복구한다.

### kube-proxy
- kubelet 이 파드의 상태를 관리한다면 kube-proxy 는 파드의 통신을 담당한다.
```shell
# m-k8s at super putty
kubectl create -f ~/_Book_k8sInfra/ch3/3.1.6/nginx-pod.yaml
kubectl get pods -o -wide
curl 172.16.103.130
```
1. 테스트하기 위해 마스터 노드인 m-k8s에서 다시 파드를 배포한다.
2. 파드의 IP 와 워커 노드를 확인한다.
3. curl(Client URL) 로 파드의 전 단계에서 확인한 파드의 IP 로 nginx 웹 서버 메인 페이지 내용을 확인한다.
```shell
# w2-k8s at super putty
modprobe -r br_netfilter
systemctl restart network
curl 172.16.103.130
kubectl get pod -o wide
modprobe br_netfilter
reboot
```
4. 워커 노드에서 br_netfilter 모듈 제거 후 네트워크를 다시 시작해 변경된 내용을 적용한다.
5. curl 로 nginx 웹 서버 페이지 정보를 받아온다.
6. 파드의 노드 위치와 IP 가 변경되지 않았는지, 작동 상태에 문제가 없는지 확인한다.
7. 워커 노드에서 br_netfilter 를 커널에 적재하고 시스템을 다시 시작해 적용한다.
```shell
# m-k8s at super putty
kubectl get pod -o wide
curl 172.16.103.131
```
8. 일정 시간이 지난 후에 m-k8s 에서 파드의 상태를 확인하면 파드가 1회 다시 시작했다는 의미로 RESTARTS 가 증가하고 IP가 변경된 것을 확인 가능하다.
9. 바뀐 IP로 curl 명령을 실행해 파드로부터 정보를 정상적으로 받아오는지 확인한다.